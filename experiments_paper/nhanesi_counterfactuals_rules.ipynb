{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e40f30c",
   "metadata": {},
   "source": [
    "### Load the data and train ACXplainer to generate Counterfactual Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11901a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Classifier: LightGBM\n",
      "\t* n_estimators: 50\n",
      "\t* num_leaves: 8\n",
      "\t* train score:  0.8414028553693358\n",
      "\t* train denied:  2249\n",
      "\t* test score:  0.8399255467659377\n",
      "\t* test denied:  762\n",
      "\n",
      "# Trained ACXplainer -- score = 0.9692880409492788\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from acv_explainers import ACXplainer\n",
    "from acv_explainers.utils import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from utils import MyTabNetClassifier\n",
    "from utils import DatasetHelper, DATASETS_NAME\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 2022    \n",
    "dataset = 'n'\n",
    "dataset_name = DATASETS_NAME[dataset]\n",
    "model= 'X'\n",
    "np.random.seed(0)\n",
    "\n",
    "if(model=='L'):\n",
    "    print('* Classifier: LogisticRegression')\n",
    "    mdl = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "    print('\\t* C: {}'.format(mdl.C)); print('\\t* penalty: {}'.format(mdl.penalty));\n",
    "elif(model=='X'):\n",
    "    print('* Classifier: LightGBM')\n",
    "    mdl = LGBMClassifier(n_estimators=50, num_leaves=8)\n",
    "    print('\\t* n_estimators: {}'.format(mdl.n_estimators)); print('\\t* num_leaves: {}'.format(mdl.num_leaves));\n",
    "elif(model=='T'):\n",
    "    print('* Classifier: TabNet')\n",
    "    mdl = MyTabNetClassifier(D.feature_types, verbose=0)\n",
    "\n",
    "\n",
    "D = DatasetHelper(dataset=dataset, feature_prefix_index=False)\n",
    "X_tr, X_ts, y_tr, y_ts = D.train_test_split()\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isolation = IsolationForest()\n",
    "isolation.fit(X_tr)\n",
    "\n",
    "mdl = mdl.fit(X_tr, y_tr, X_vl=X_ts, y_vl=y_ts) if model=='T' else mdl.fit(X_tr, y_tr)\n",
    "X = X_tr[mdl.predict(X_tr)==1]; X_vl = X_ts[mdl.predict(X_ts)==1];\n",
    "print('\\t* train score: ', mdl.score(X_tr, y_tr)); print('\\t* train denied: ', X.shape[0]);\n",
    "print('\\t* test score: ', mdl.score(X_ts, y_ts)); print('\\t* test denied: ', X_vl.shape[0]); print();\n",
    "\n",
    "x_train = X_tr.copy()\n",
    "x_test = X_ts.copy()\n",
    "y_train = mdl.predict(X_tr)\n",
    "y_test = mdl.predict(X_ts)\n",
    "\n",
    "### Train Explainer (ACXplainer)\n",
    "ac_explainer = ACXplainer(classifier=True, n_estimators=20, max_depth=12)\n",
    "ac_explainer.fit(x_train, y_train)\n",
    "\n",
    "print('# Trained ACXplainer -- score = {}'.format(accuracy_score(y_test, ac_explainer.predict(x_test))))\n",
    "\n",
    "# idx = 0\n",
    "# size = idx + 500\n",
    "x, y = x_test[:500], y_test[:500]\n",
    "x_rules, y_rules = x_train[:1000], y_train[:1000]\n",
    "\n",
    "columns_name = D.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eead28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = RunExperiments(ac_explainer, x_train, x_test, y_train, y_test, columns_name, model=mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dbece47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Computing the local divergent set of (x, y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:00<00:00, 96.08it/s]\n",
      " 38%|████████████████▉                            | 3/8 [00:33<00:56, 11.30s/it]\n"
     ]
    }
   ],
   "source": [
    "results.run_local_divergent_set(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "917d02e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Computing the local counterfactual rules of (x, y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 281/281 [04:24<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "results.run_local_counterfactual_rules(x, y, acc_level=0.9, pi_level=0.9)\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "495a09b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Computing the local counterfactual rules of (x, y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 281/281 [04:19<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "results.run_local_counterfactual_rules(x, y, acc_level=0.9, pi_level=0.9)\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0c86281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Sampling using the local counterfactual rules of (x, y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 281/281 [15:53<00:00,  3.39s/it]\n"
     ]
    }
   ],
   "source": [
    "results.run_sampling_local_counterfactuals(x, y, batch=1000, max_iter=1000, temp=0.5)\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73cc5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Accuracy = 0.961038961038961 -- Local Coverage = 0.8220640569395018\n"
     ]
    }
   ],
   "source": [
    "print('Local Accuracy = {} -- Local Coverage = {}'.format(results.accuracy_local, results.coverage_local))\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a7314bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Computing the Sufficient Explanations and the Sufficient Rules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 8/8 [00:54<00:00,  6.78s/it]\n",
      "100%|███████████████████████████████████████| 1000/1000 [07:26<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "results.run_sufficient_rules(x_rules, y_rules, pi_level=0.9)\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "349ca92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Computing the regional divergent set of (x, y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▉                            | 3/8 [02:49<04:42, 56.42s/it]\n"
     ]
    }
   ],
   "source": [
    "results.run_regional_divergent_set(stop=True, pi_level=0.9)\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef76b42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Computing the regional counterfactual rules of (x, y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [11:00<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "results.run_regional_counterfactual_rules(acc_level=0.9, pi_level=0.9)\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a019514d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Sampling using the regional counterfactual rules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 281/281 [14:05<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "results.run_sampling_regional_counterfactuals_alltests(max_obs=x_test.shape[0],batch=1000, max_iter=1000, temp=0.5)\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29a95ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regional Accuracy = 0.9948717948717949 -- Regional Coverage = 0.693950177935943\n"
     ]
    }
   ],
   "source": [
    "print('Regional Accuracy = {} -- Regional Coverage = {}'.format(results.accuracy_regional, results.coverage_regional))\n",
    "save_model(results, name='{}CR_results'.format(D.dataset_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d93ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5855bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONSISTENT\n"
     ]
    }
   ],
   "source": [
    "if np.mean(mdl.predict(results.x_test) == results.y_test):\n",
    "    print('CONSISTENT')\n",
    "else:\n",
    "    raise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "070b0884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all acc 1.0\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for i, c in enumerate(results.counterfactuals_samples_local):\n",
    "    if len(c) !=0:\n",
    "        x.append(results.x_test[i])\n",
    "\n",
    "x = np.array(x)\n",
    "ce = np.array(results.dist_local)\n",
    "ce_r = np.array(results.dist_regional)\n",
    "\n",
    "print('all acc', np.mean(mdl.predict(x_test) != mdl.predict(ce_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "295e4502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL positive accuracy 0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "x_pos = x[mdl.predict(x) == 1]\n",
    "ce_pos = ce[mdl.predict(x) == 1]\n",
    "\n",
    "print('LOCAL positive accuracy', np.mean(mdl.predict(x_pos) != mdl.predict(ce_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5d240afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL positive sparsity 3.4857142857142858\n"
     ]
    }
   ],
   "source": [
    "print('LOCAL positive sparsity', np.mean(np.sum(x_pos-ce_pos!=0, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "27a25ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL positive inlier 0.9904761904761905\n"
     ]
    }
   ],
   "source": [
    "inlier_pos = np.mean(results.isolation.predict(ce_pos) == 1)\n",
    "print('LOCAL positive inlier', inlier_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215141d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "160ad64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL negative accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "x_neg = x[mdl.predict(x) == 0]\n",
    "ce_neg = ce[mdl.predict(x) == 0]\n",
    "\n",
    "print('LOCAL negative accuracy', np.mean(mdl.predict(x_neg) != mdl.predict(ce_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "235c272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL negative sparsity 3.8174603174603177\n"
     ]
    }
   ],
   "source": [
    "print('LOCAL negative sparsity', np.mean(np.sum(x_neg-ce_neg!=0, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b78e62ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL negative inlier 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "inlier_neg = np.mean(results.isolation.predict(ce_neg) == 1)\n",
    "print('LOCAL negative inlier', inlier_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidate(x, S, x_train, C_S, n_samples):\n",
    "    \"\"\"\n",
    "    Generate sample by sampling marginally between the training observations.\n",
    "    Args:\n",
    "        x (numpy.ndarray)): 1-D array, an observation \n",
    "        S (list): contains the indices of the variables on which to condition\n",
    "        x_train (numpy.ndarray)): 2-D array represent the training samples\n",
    "        C_S (numpy.ndarray)): 3-D (#variables x 2 x 1) representing the hyper-rectangle on which to condition\n",
    "        n_samples (int): number of samples \n",
    "    Returns:\n",
    "        The generated samples\n",
    "    \"\"\"\n",
    "    x_poss = [x_train[(C_S[i, 0] <= x_train[:, i]) * (x_train[:, i] <= C_S[i, 1]), i] for i in S]\n",
    "    x_cand = np.repeat(x.reshape(1, -1), repeats=n_samples, axis=0)\n",
    "    \n",
    "    for i in range(len(S)):\n",
    "        rdm_id = np.random.randint(low=0, high=x_poss[i].shape[0], size=n_samples)\n",
    "        x_cand[:, S[i]] = x_poss[i][rdm_id]\n",
    "\n",
    "    return x_cand\n",
    "\n",
    "\n",
    "def simulated_annealing(outlier_score, x, S, x_train, C_S, batch, max_iter, temp, max_iter_convergence):\n",
    "    \"\"\"\n",
    "    Generate sample s.t. (X | X_S \\in C_S) using simulated annealing and outlier score.\n",
    "    Args:\n",
    "        outlier_score (lambda functon): outlier_score(X) return a outlier score. If the value are negative, then the observation is an outlier.\n",
    "        x (numpy.ndarray)): 1-D array, an observation \n",
    "        S (list): contains the indices of the variables on which to condition\n",
    "        x_train (numpy.ndarray)): 2-D array represent the training samples\n",
    "        C_S (numpy.ndarray)): 3-D (#variables x 2 x 1) representing the hyper-rectangle on which to condition\n",
    "        batch (int): number of sample by iteration\n",
    "        max_iter (int): number of iteration of the algorithm\n",
    "        temp (double): the temperature of the simulated annealing algorithm\n",
    "        max_iter_convergence (double): minimun number of iteration to stop the algorithm if it find an in-distribution observation\n",
    "\n",
    "    Returns:\n",
    "        The generated sample, and its outlier score\n",
    "    \"\"\"\n",
    "    \n",
    "    best = generate_candidate(x, S, x_train, C_S, n_samples=1)\n",
    "    best_eval = outlier_score(best)[0]\n",
    "    curr, curr_eval = best, best_eval\n",
    "\n",
    "    it = 0\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        x_cand = generate_candidate(curr, S, x_train, C_S, batch)\n",
    "        score_candidates = outlier_score(x_cand)\n",
    "\n",
    "        candidate_eval = np.max(score_candidates)\n",
    "        candidate = x_cand[np.argmax(score_candidates)]\n",
    "\n",
    "        if candidate_eval > best_eval:\n",
    "            best, best_eval = candidate, candidate_eval\n",
    "            it = 0\n",
    "        else:\n",
    "            it += 1\n",
    "\n",
    "        # check convergence\n",
    "        if best_eval > 0 and it > max_iter_convergence:\n",
    "            break\n",
    "\n",
    "        diff = candidate_eval - curr_eval\n",
    "        t = temp / np.log(float(i + 1))\n",
    "        metropolis = np.exp(-diff / t)\n",
    "\n",
    "        if diff > 0 or rand() < metropolis:\n",
    "            curr, curr_eval = candidate, candidate_eval\n",
    "\n",
    "    return best, best_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e2c94e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGIONAL positive inlier 0.8782608695652174\n"
     ]
    }
   ],
   "source": [
    "inlier_pos = np.mean(results.isolation.predict(ce_pos_r) == 1)\n",
    "print('REGIONAL positive inlier', inlier_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a8e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "049b58fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regional Accuracy = 0.9948717948717949\n"
     ]
    }
   ],
   "source": [
    "print('Regional Accuracy = {}'.format(results.accuracy_regional))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0c2d2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Coverage = 0.8220640569395018 -- Global Coverage 0.693950177935943\n"
     ]
    }
   ],
   "source": [
    "print('Local Coverage = {} -- Global Coverage {}'.format(results.coverage_local, \n",
    "                                                        results.coverage_regional))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
